{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  loinc_num                                     name  \\\n",
      "0    1988-5  component reactive protein serum plasma   \n",
      "1    1959-6                        bicarbonate blood   \n",
      "2   10331-7                                 rh blood   \n",
      "3   18998-5            trimethoprim sulfamethoxazole   \n",
      "4    1975-2             bilirubin total serum plasma   \n",
      "\n",
      "                       component        system                 property  \\\n",
      "0     component reactive protein  serum plasma       mass concentration   \n",
      "1                    bicarbonate         blood  substance concentration   \n",
      "2                             rh         blood                     type   \n",
      "3  trimethoprim sulfamethoxazole       isolate           susceptibility   \n",
      "4                      bilirubin  serum plasma       mass concentration   \n",
      "\n",
      "  measurement_type  \n",
      "0                   \n",
      "1                   \n",
      "2                   \n",
      "3                   \n",
      "4                   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning: Renaming and Extracting Measurement Type\n",
    "\n",
    "This script performs two data cleaning operations:\n",
    "\n",
    "1. **Renaming Columns**  \n",
    "2. **Extracting and Removing Measurement Types from Names**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  loinc_num                                     name  \\\n",
      "0    1988-5  component reactive protein serum plasma   \n",
      "1    1959-6                        bicarbonate blood   \n",
      "2   10331-7                                 rh blood   \n",
      "3   18998-5            trimethoprim sulfamethoxazole   \n",
      "4    1975-2             bilirubin total serum plasma   \n",
      "\n",
      "                       component        system                 property  \\\n",
      "0     component reactive protein  serum plasma       mass concentration   \n",
      "1                    bicarbonate         blood  substance concentration   \n",
      "2                             rh         blood                     type   \n",
      "3  trimethoprim sulfamethoxazole       isolate           susceptibility   \n",
      "4                      bilirubin  serum plasma       mass concentration   \n",
      "\n",
      "  measurement_type  \n",
      "0                   \n",
      "1                   \n",
      "2                   \n",
      "3                   \n",
      "4                   \n"
     ]
    }
   ],
   "source": [
    "df.rename(columns={\"long_common_name\": \"name\"}, inplace=True)\n",
    "\n",
    "df[\"measurement_type\"] = df[\"name\"].apply(lambda x: re.findall(r\"\\[(.*?)\\]\", x)[0] if \"[\" in x else \"\")\n",
    "df[\"name\"] = df[\"name\"].apply(lambda x: re.sub(r\"\\[.*?\\]\", \"\", x).strip() if isinstance(x, str) else x)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abbreviation Mapping, Stop Words, and Lemmatization\n",
    "\n",
    "This script performs **text preprocessing** by:\n",
    "- Expanding **abbreviations** into full terms using the dictionary `abbreviation_mapping`.\n",
    "- Removing **common stop words**.\n",
    "- Applying **lemmatization** to reduce words to their base forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joseantonioruizheredia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/joseantonioruizheredia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "abbreviation_mapping = {\n",
    "    'c': 'component',\n",
    "    'mcnc': 'mass concentration',\n",
    "    'bld': 'blood',\n",
    "    'scnc': 'substance concentration',\n",
    "    'susc': 'susceptibility',\n",
    "    'acnc': 'amount concentration',\n",
    "    'plas': 'plasma',\n",
    "    'ccnc': 'cell concentration',\n",
    "    'ncnc': 'number concentration',\n",
    "    'XXX': 'unknown',\n",
    "    '^bpu': 'body part or unit',\n",
    "    'fld': 'field',\n",
    "    'abo': 'abo blood group',\n",
    "    'ser': 'serum',\n",
    "    'mscnc': 'mass substance concentration'\n",
    "}\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing in a DataFrame\n",
    "\n",
    "This script performs text cleaning and abbreviation replacement on text columns in a DataFrame (`df`). It helps standardize text data for further analysis by removing noise and ensuring consistency.\n",
    "\n",
    "## Functions\n",
    "\n",
    "### 1. clean_text\n",
    "Cleans a given text string by:\n",
    "1. Converting it to **lowercase**.\n",
    "2. Removing **punctuation** (replacing non-alphanumeric characters with spaces).\n",
    "3. **Tokenizing** (splitting the text into words).\n",
    "4. Removing **stop words** (common words that don't contribute much meaning).\n",
    "5. Applying **lemmatization** (reducing words to their base form).\n",
    "\n",
    "If the input is not a string, it returns an empty string.\n",
    "\n",
    "### 2. replace_abbreviations\n",
    "Replaces known abbreviations in a given text using the `abbreviation_mapping` dictionary.\n",
    "- Splits the text into words.\n",
    "- Replaces each word if it exists in the abbreviation dictionary.\n",
    "- Returns the modified text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  loinc_num                                      name  \\\n",
      "0    1988-5   component reactive protein serum plasma   \n",
      "1    1959-6                         bicarbonate blood   \n",
      "2   10331-7                                  rh blood   \n",
      "3   18998-5             trimethoprim sulfamethoxazole   \n",
      "4    1975-2              bilirubin total serum plasma   \n",
      "5     890-4  blood group antibody screen serum plasma   \n",
      "6   20565-8                carbon dioxide total blood   \n",
      "7   18906-8                             ciprofloxacin   \n",
      "8    2143-6                     cortisol serum plasma   \n",
      "9    2075-0                     chloride serum plasma   \n",
      "\n",
      "                       component        system                 property  \\\n",
      "0     component reactive protein  serum plasma       mass concentration   \n",
      "1                    bicarbonate         blood  substance concentration   \n",
      "2                             rh         blood                     type   \n",
      "3  trimethoprim sulfamethoxazole       isolate           susceptibility   \n",
      "4                      bilirubin  serum plasma       mass concentration   \n",
      "5    blood group antibody screen  serum plasma     amount concentration   \n",
      "6                 carbon dioxide         blood  substance concentration   \n",
      "7                  ciprofloxacin       isolate           susceptibility   \n",
      "8                       cortisol  serum plasma       mass concentration   \n",
      "9                       chloride  serum plasma  substance concentration   \n",
      "\n",
      "  measurement_type  \n",
      "0                   \n",
      "1                   \n",
      "2                   \n",
      "3                   \n",
      "4                   \n",
      "5                   \n",
      "6                   \n",
      "7                   \n",
      "8                   \n",
      "9                   \n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower() \n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)  \n",
    "        words = text.split()  \n",
    "        words = [word for word in words if word not in stop_words]  \n",
    "        words = [lemmatizer.lemmatize(word) for word in words] \n",
    "        return \" \".join(words)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def replace_abbreviations(text):\n",
    "    if isinstance(text, str):\n",
    "        words = text.split()\n",
    "        words = [abbreviation_mapping.get(word, word) for word in words]  \n",
    "        return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    if col != \"loinc_num\":  \n",
    "        df[col] = df[col].apply(clean_text)\n",
    "        df[col] = df[col].apply(replace_abbreviations)\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Weights and Embedding Model Initialization\n",
    "\n",
    "This script defines **column weights** for a scoring system and initializes an **embedding model** for text similarity calculations.\n",
    "\n",
    "## Column Weights\n",
    "\n",
    "The `column_weights` dictionary assigns importance to different columns when calculating scores:\n",
    "\n",
    "- **Higher weights** (e.g., `name`, `component`) indicate greater importance in the scoring process.\n",
    "- `loinc_num` has a weight of **0** because it is likely an identifier and does not contribute to similarity calculations.\n",
    "\n",
    "## Embedding Model Initialization\n",
    "\n",
    "The script attempts to load an embedding model for text similarity using **SentenceTransformer**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_weights = {\n",
    "    'name': 1.5,\n",
    "    'component': 4.0,\n",
    "    'long_common_name': 1.0,\n",
    "    'system': 3.0,\n",
    "    'property': 1.0,\n",
    "    'measurement_type': 1.0,\n",
    "    'loinc_num': 0\n",
    "}\n",
    "\n",
    "global embedding_model\n",
    "if 'embedding_model' not in globals():\n",
    "    try:\n",
    "        embedding_model = SentenceTransformer('pritamdeka/BioBERT-MNLI')\n",
    "    except:\n",
    "        try:\n",
    "            embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        except:\n",
    "            embedding_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevance Score Calculation\n",
    "This script calculates a **relevance score** for each row in a dataset by comparing a query to the dataset's text fields using both **traditional keyword matching** and **semantic similarity via embeddings**.\n",
    "\n",
    "\n",
    "### 1. calculate_score\n",
    "This function calculates the relevance score for a given row by:\n",
    "1. Splitting the query into words and storing them in a set.\n",
    "2. Initializing an empty dictionary to track matched words.\n",
    "3. Computing the **traditional** relevance score.\n",
    "4. Computing the **embedding-based** relevance score.\n",
    "5. Combining both scores and optionally printing debug information.\n",
    "\n",
    "\n",
    "### 2. get_query_embedding\n",
    "Encodes the query into an **embedding vector** using a pre-trained embedding model.\n",
    "- If the embedding model is available, it encodes the query.\n",
    "- If an error occurs, it prints an error message and returns `None`.\n",
    "\n",
    "### 3. calculate_traditional_score\n",
    "This function calculates a **keyword matching score** based on:\n",
    "- The presence of query words in text fields of the row.\n",
    "- A predefined weight assigned to each column.\n",
    "- Only the highest weight for each word is considered.\n",
    "\n",
    "### 4. calculate_embedding_score\n",
    "This function computes the **semantic similarity score** between the query embedding and the row's text fields:\n",
    "- Encodes the text field into an embedding.\n",
    "- Uses **cosine similarity** to measure similarity between the query and field.\n",
    "- Converts the similarity score (ranging from -1 to 1) into a normalized range (0 to 5).\n",
    "- Applies column weights to adjust the score.\n",
    "- Adds the result to the final score.\n",
    "\n",
    "## Execution Process\n",
    "1. The script calculates the **relevance score** for each row using the `apply` function.\n",
    "2. For the first five rows, debugging is enabled to print detailed matching information.\n",
    "3. The relevance scores are merged into `df_original` based on `loinc_num`.\n",
    "4. The final results are saved to a CSV file and printed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(query, row, debug=False):\n",
    "    global min_score, max_score\n",
    "    \n",
    "    query_words = set(query.lower().split())  # \n",
    "    matched_words = {}  \n",
    "\n",
    "    query_embedding = get_query_embedding(query)\n",
    "    debug_info = {\"query\": query, \"matched_words\": {}, \"embedding_scores\": []}\n",
    "\n",
    "    score = calculate_traditional_score(query_words, row, matched_words, debug_info)\n",
    "    score += calculate_embedding_score(query_embedding, row, debug_info)\n",
    "\n",
    "    debug_info[\"matched_words\"] = matched_words\n",
    "    debug_info[\"final_score\"] = score\n",
    "    \n",
    "    if debug:\n",
    "        print(debug_info)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def get_query_embedding(query):\n",
    "    if embedding_model:\n",
    "        try:\n",
    "            return embedding_model.encode(query.lower())\n",
    "        except Exception as e:\n",
    "            print(f\"Embedding encoding error: {e}\")\n",
    "    return None\n",
    "\n",
    "def calculate_traditional_score(query_words, row, matched_words, debug_info):\n",
    "    score = 0\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        if col in row and pd.notna(row[col]):\n",
    "            cell_text = str(row[col]).lower()\n",
    "            cell_words = set(cell_text.split())\n",
    "            weight = column_weights.get(col, 1.0)\n",
    "\n",
    "            new_matched_words = query_words & cell_words\n",
    "            for word in new_matched_words:\n",
    "                if word not in matched_words or weight > matched_words[word]:\n",
    "                    matched_words[word] = weight  \n",
    "    return score\n",
    "\n",
    "def calculate_embedding_score(query_embedding, row, debug_info):\n",
    "    score = 0\n",
    "    if embedding_model and query_embedding is not None:\n",
    "        for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "            if col in row and pd.notna(row[col]):\n",
    "                cell_text = str(row[col]).lower()\n",
    "                weight = column_weights.get(col, 1.0)\n",
    "                try:\n",
    "                    cell_embedding = embedding_model.encode(cell_text)\n",
    "                    similarity = cosine_similarity([query_embedding], [cell_embedding])[0][0]\n",
    "                    embedding_score = ((similarity + 1) / 2) * 5 * weight\n",
    "                    score += embedding_score\n",
    "                    debug_info[\"embedding_scores\"].append({\"column\": col, \"similarity\": similarity, \"score\": embedding_score})\n",
    "                except Exception as e:\n",
    "                    print(f\"Embedding similarity error: {e}\")\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'glucose in blood', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(0.082764), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.0109481625), 'score': np.float32(10.109482)}, {'column': 'system', 'similarity': np.float32(0.026590478), 'score': np.float32(7.6994286)}, {'column': 'property', 'similarity': np.float32(-0.10000585), 'score': np.float32(2.2499852)}], 'final_score': np.float32(20.058895)}\n",
      "{'query': 'glucose in blood', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(0.1021516), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.14276442), 'score': np.float32(11.427645)}, {'column': 'system', 'similarity': np.float32(-0.00083919987), 'score': np.float32(7.4937067)}, {'column': 'property', 'similarity': np.float32(-0.043209463), 'score': np.float32(2.3919764)}], 'final_score': np.float32(21.313328)}\n",
      "{'query': 'glucose in blood', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(-0.00916206), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.062415443), 'score': np.float32(10.624155)}, {'column': 'system', 'similarity': np.float32(-0.00083919987), 'score': np.float32(7.4937067)}, {'column': 'property', 'similarity': np.float32(-0.016309056), 'score': np.float32(2.4592273)}], 'final_score': np.float32(20.57709)}\n",
      "{'query': 'glucose in blood', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(0.05942208), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.058590345), 'score': np.float32(10.585903)}, {'column': 'system', 'similarity': np.float32(0.014001254), 'score': np.float32(7.6050096)}, {'column': 'property', 'similarity': np.float32(-0.021907914), 'score': np.float32(2.4452302)}], 'final_score': np.float32(20.636143)}\n",
      "{'query': 'glucose in blood', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(0.07096303), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.11009472), 'score': np.float32(11.100946)}, {'column': 'system', 'similarity': np.float32(0.026590478), 'score': np.float32(7.6994286)}, {'column': 'property', 'similarity': np.float32(-0.10000585), 'score': np.float32(2.2499852)}], 'final_score': np.float32(21.05036)}\n",
      "{'query': 'bilirubin in plasma', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(-0.027602732), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.3006523), 'score': np.float32(13.006523)}, {'column': 'system', 'similarity': np.float32(0.043820284), 'score': np.float32(7.8286524)}, {'column': 'property', 'similarity': np.float32(-0.03198865), 'score': np.float32(2.4200284)}], 'final_score': np.float32(23.255203)}\n",
      "{'query': 'bilirubin in plasma', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(0.037488956), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.18759102), 'score': np.float32(11.875911)}, {'column': 'system', 'similarity': np.float32(-0.0054464303), 'score': np.float32(7.4591517)}, {'column': 'property', 'similarity': np.float32(-0.066928454), 'score': np.float32(2.3326788)}], 'final_score': np.float32(21.66774)}\n",
      "{'query': 'bilirubin in plasma', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(0.04318215), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.081342384), 'score': np.float32(10.813423)}, {'column': 'system', 'similarity': np.float32(0.13492452), 'score': np.float32(8.511934)}, {'column': 'property', 'similarity': np.float32(-0.083230734), 'score': np.float32(2.291923)}], 'final_score': np.float32(21.617281)}\n",
      "{'query': 'bilirubin in plasma', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(-0.057907823), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.3698172), 'score': np.float32(13.698173)}, {'column': 'system', 'similarity': np.float32(0.13492452), 'score': np.float32(8.511934)}, {'column': 'property', 'similarity': np.float32(-0.083230734), 'score': np.float32(2.291923)}], 'final_score': np.float32(24.50203)}\n",
      "{'query': 'bilirubin in plasma', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(-0.015002159), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.15958723), 'score': np.float32(11.595873)}, {'column': 'system', 'similarity': np.float32(0.077237196), 'score': np.float32(8.079279)}, {'column': 'property', 'similarity': np.float32(-0.025351064), 'score': np.float32(2.4366224)}], 'final_score': np.float32(22.111774)}\n",
      "{'query': 'white blood cells count', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(-0.0070717335), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.11145176), 'score': np.float32(11.114517)}, {'column': 'system', 'similarity': np.float32(-0.02031454), 'score': np.float32(7.347641)}, {'column': 'property', 'similarity': np.float32(-0.070905), 'score': np.float32(2.3227377)}], 'final_score': np.float32(20.784897)}\n",
      "{'query': 'white blood cells count', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(0.018132187), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.06945392), 'score': np.float32(10.69454)}, {'column': 'system', 'similarity': np.float32(0.029126318), 'score': np.float32(7.7184467)}, {'column': 'property', 'similarity': np.float32(0.056446463), 'score': np.float32(2.6411161)}], 'final_score': np.float32(21.054104)}\n",
      "{'query': 'white blood cells count', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(-0.0076852455), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.11145176), 'score': np.float32(11.114517)}, {'column': 'system', 'similarity': np.float32(-0.022640834), 'score': np.float32(7.330194)}, {'column': 'property', 'similarity': np.float32(-0.005472062), 'score': np.float32(2.4863198)}], 'final_score': np.float32(20.931032)}\n",
      "{'query': 'white blood cells count', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(-0.0041115694), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.07826918), 'score': np.float32(10.782692)}, {'column': 'system', 'similarity': np.float32(0.009982513), 'score': np.float32(7.5748687)}, {'column': 'property', 'similarity': np.float32(-0.05428858), 'score': np.float32(2.3642786)}], 'final_score': np.float32(20.72184)}\n",
      "{'query': 'white blood cells count', 'matched_words': {}, 'embedding_scores': [{'column': 'loinc_num', 'similarity': np.float32(0.10908297), 'score': np.float32(0.0)}, {'column': 'component', 'similarity': np.float32(0.024809264), 'score': np.float32(10.248093)}, {'column': 'system', 'similarity': np.float32(0.009982513), 'score': np.float32(7.5748687)}, {'column': 'property', 'similarity': np.float32(-0.05428858), 'score': np.float32(2.3642786)}], 'final_score': np.float32(20.18724)}\n",
      "CSV with relevance scores has been saved as 'dataset_with_scores.csv'.\n"
     ]
    }
   ],
   "source": [
    "def preprocess(excel_file):\n",
    "    \"\"\"\n",
    "    Function to preprocess the Excel file and compute relevance scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    xl = pd.ExcelFile(excel_file)\n",
    "\n",
    "    for sheet_name in xl.sheet_names:\n",
    "        query_df = xl.parse(sheet_name, header=2)\n",
    "        sheet_name = sheet_name.lower() \n",
    "        \n",
    "        query_df.columns = query_df.columns.str.strip()  # Remove extra spaces from column names\n",
    "        \n",
    "        if len(query_df.columns) < 4:\n",
    "            print(f\"Skipping sheet '{sheet_name}': Missing required columns\")\n",
    "            continue\n",
    "        \n",
    "        for index, row in query_df.iterrows():\n",
    "            score = calculate_score(sheet_name, row, debug=True if row.name < 5 else False)\n",
    "            results.append([sheet_name, row.iloc[0], row.iloc[1], score])\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=[\"Query\", \"LOINC Code\", \"Name\", \"Score\"])\n",
    "\n",
    "    min_score = results_df[\"Score\"].min()\n",
    "    max_score = results_df[\"Score\"].max()\n",
    "\n",
    "    results_df[\"Normalized_Score\"] = results_df[\"Score\"].apply(lambda score: (score - min_score) / (max_score - min_score) if max_score != min_score else 1.0)\n",
    "\n",
    "    results_df.to_csv(\"dataset_with_scores.csv\", index=False)\n",
    "    print(\"CSV with relevance scores has been saved as 'dataset_with_scores.csv'.\")\n",
    "\n",
    "\n",
    "\n",
    "file_path = \"./loinc_dataset-v2.xlsx\"\n",
    "results_df = preprocess(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
