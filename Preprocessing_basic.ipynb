{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of sheet: glucose in blood\n",
      "  loinc_num                                   long_common_name  \\\n",
      "0    1988-5  C reactive protein [Mass/volume] in Serum or P...   \n",
      "1    1959-6                Bicarbonate [Moles/volume] in Blood   \n",
      "2   10331-7                                 Rh [Type] in Blood   \n",
      "3   18998-5     Trimethoprim+Sulfamethoxazole [Susceptibility]   \n",
      "4    1975-2   Bilirubin.total [Mass/volume] in Serum or Plasma   \n",
      "\n",
      "                       component    system property  \n",
      "0             C reactive protein  Ser/Plas     MCnc  \n",
      "1                    Bicarbonate       Bld     SCnc  \n",
      "2                             Rh       Bld     Type  \n",
      "3  Trimethoprim+Sulfamethoxazole   Isolate     Susc  \n",
      "4                      Bilirubin  Ser/Plas     MCnc  \n",
      "\n",
      "\n",
      "First 5 rows of sheet: bilirubin in plasma\n",
      "  loinc_num                                   long_common_name  \\\n",
      "0     934-0                          Blood product unit ID [#]   \n",
      "1    1742-6  Alanine aminotransferase [Enzymatic activity/v...   \n",
      "2   20565-8      Carbon dioxide, total [Moles/volume] in Blood   \n",
      "3    1959-6                Bicarbonate [Moles/volume] in Blood   \n",
      "4   18906-8                     Ciprofloxacin [Susceptibility]   \n",
      "\n",
      "                  component    system property  \n",
      "0     Blood product unit ID      Dose      Num  \n",
      "1  Alanine aminotransferase  Ser/Plas     CCnc  \n",
      "2            Carbon dioxide       Bld     SCnc  \n",
      "3               Bicarbonate       Bld     SCnc  \n",
      "4             Ciprofloxacin   Isolate     Susc  \n",
      "\n",
      "\n",
      "First 5 rows of sheet: white blood cells count\n",
      "  loinc_num                                   long_common_name  \\\n",
      "0   33870-7  Bilirubin.total [Presence] in Unspecified spec...   \n",
      "1   29265-6  Calcium [Moles/volume] corrected for albumin i...   \n",
      "2   14423-8    Bilirubin.total [Mass/volume] in Synovial fluid   \n",
      "3   23658-8                  Other Antibiotic [Susceptibility]   \n",
      "4   19000-9                        Vancomycin [Susceptibility]   \n",
      "\n",
      "                        component    system property  \n",
      "0                       Bilirubin       XXX    PrThr  \n",
      "1  Calcium^^corrected for albumin  Ser/Plas     SCnc  \n",
      "2                       Bilirubin  Synv fld     MCnc  \n",
      "3                  Antibiotic XXX   Isolate     Susc  \n",
      "4                      Vancomycin   Isolate     Susc  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "query_mapping = {\n",
    "    \"glucose in blood\": {\n",
    "        \"component\": \"glucose\",\n",
    "        \"system\": \"blood\"\n",
    "    },\n",
    "    \"bilirubin in plasma\": {\n",
    "        \"component\": \"bilirubin\",\n",
    "        \"system\": \"plasma\"\n",
    "    },\n",
    "    \"white blood cells count\": {\n",
    "        \"component\": \"leukocytes\",\n",
    "        \"system\": \"blood\"\n",
    "    }\n",
    "}\n",
    "\n",
    "file_path = \"./loinc_dataset-v2.xlsx\"\n",
    "xl = pd.ExcelFile(file_path)\n",
    "\n",
    "for sheet_name in xl.sheet_names:\n",
    "    query_df = xl.parse(sheet_name, header=2)\n",
    "    sheet_name = sheet_name.lower() \n",
    "    \n",
    "    print(f\"First 5 rows of sheet: {sheet_name}\")\n",
    "    print(query_df.head()) \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning: Renaming and Extracting Measurement Type\n",
    "\n",
    "This script performs two data cleaning operations:\n",
    "\n",
    "1. **Renaming Columns**  \n",
    "2. **Extracting and Removing Measurement Types from Names**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of sheet: glucose in blood\n",
      "  loinc_num                                    name  \\\n",
      "0    1988-5  C reactive protein  in Serum or Plasma   \n",
      "1    1959-6                   Bicarbonate  in Blood   \n",
      "2   10331-7                            Rh  in Blood   \n",
      "3   18998-5           Trimethoprim+Sulfamethoxazole   \n",
      "4    1975-2     Bilirubin.total  in Serum or Plasma   \n",
      "\n",
      "                       component    system property measurement_type  \n",
      "0             C reactive protein  Ser/Plas     MCnc      Mass/volume  \n",
      "1                    Bicarbonate       Bld     SCnc     Moles/volume  \n",
      "2                             Rh       Bld     Type             Type  \n",
      "3  Trimethoprim+Sulfamethoxazole   Isolate     Susc   Susceptibility  \n",
      "4                      Bilirubin  Ser/Plas     MCnc      Mass/volume  \n",
      "\n",
      "\n",
      "First 5 rows of sheet: bilirubin in plasma\n",
      "  loinc_num                                          name  \\\n",
      "0     934-0                         Blood product unit ID   \n",
      "1    1742-6  Alanine aminotransferase  in Serum or Plasma   \n",
      "2   20565-8               Carbon dioxide, total  in Blood   \n",
      "3    1959-6                         Bicarbonate  in Blood   \n",
      "4   18906-8                                 Ciprofloxacin   \n",
      "\n",
      "                  component    system property           measurement_type  \n",
      "0     Blood product unit ID      Dose      Num                          #  \n",
      "1  Alanine aminotransferase  Ser/Plas     CCnc  Enzymatic activity/volume  \n",
      "2            Carbon dioxide       Bld     SCnc               Moles/volume  \n",
      "3               Bicarbonate       Bld     SCnc               Moles/volume  \n",
      "4             Ciprofloxacin   Isolate     Susc             Susceptibility  \n",
      "\n",
      "\n",
      "First 5 rows of sheet: white blood cells count\n",
      "  loinc_num                                               name  \\\n",
      "0   33870-7           Bilirubin.total  in Unspecified specimen   \n",
      "1   29265-6  Calcium  corrected for albumin in Serum or Plasma   \n",
      "2   14423-8                 Bilirubin.total  in Synovial fluid   \n",
      "3   23658-8                                   Other Antibiotic   \n",
      "4   19000-9                                         Vancomycin   \n",
      "\n",
      "                        component    system property measurement_type  \n",
      "0                       Bilirubin       XXX    PrThr         Presence  \n",
      "1  Calcium^^corrected for albumin  Ser/Plas     SCnc     Moles/volume  \n",
      "2                       Bilirubin  Synv fld     MCnc      Mass/volume  \n",
      "3                  Antibiotic XXX   Isolate     Susc   Susceptibility  \n",
      "4                      Vancomycin   Isolate     Susc   Susceptibility  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sheet_name in xl.sheet_names:\n",
    "    query_df = xl.parse(sheet_name, header=2)\n",
    "    sheet_name = sheet_name.lower() \n",
    "    query_df.rename(columns={\"long_common_name\": \"name\"}, inplace=True)\n",
    "\n",
    "    query_df[\"measurement_type\"] = query_df[\"name\"].apply(lambda x: re.findall(r\"\\[(.*?)\\]\", x)[0] if \"[\" in x else \"\")\n",
    "    query_df[\"name\"] = query_df[\"name\"].apply(lambda x: re.sub(r\"\\[.*?\\]\", \"\", x).strip() if isinstance(x, str) else x)\n",
    "\n",
    "    print(f\"First 5 rows of sheet: {sheet_name}\")\n",
    "    print(query_df.head()) \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abbreviation Mapping, Stop Words, and Lemmatization\n",
    "\n",
    "This script performs **text preprocessing** by:\n",
    "- Expanding **abbreviations** into full terms using the dictionary `abbreviation_mapping`.\n",
    "- Removing **common stop words**.\n",
    "- Applying **lemmatization** to reduce words to their base forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joseantonioruizheredia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/joseantonioruizheredia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "abbreviation_mapping = {\n",
    "    'c': 'component',\n",
    "    'mcnc': 'mass concentration',\n",
    "    'bld': 'blood',\n",
    "    'scnc': 'substance concentration',\n",
    "    'susc': 'susceptibility',\n",
    "    'acnc': 'amount concentration',\n",
    "    'plas': 'plasma',\n",
    "    'ccnc': 'cell concentration',\n",
    "    'ncnc': 'number concentration',\n",
    "    'XXX': 'unknown',\n",
    "    '^bpu': 'body part or unit',\n",
    "    'fld': 'field',\n",
    "    'abo': 'abo blood group',\n",
    "    'ser': 'serum',\n",
    "    'mscnc': 'mass substance concentration'\n",
    "}\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing in a DataFrame\n",
    "\n",
    "This script performs text cleaning and abbreviation replacement on text columns in a DataFrame (`df`). It helps standardize text data for further analysis by removing noise and ensuring consistency.\n",
    "\n",
    "## Functions\n",
    "\n",
    "### 1. clean_text\n",
    "Cleans a given text string by:\n",
    "1. Converting it to **lowercase**.\n",
    "2. Removing **punctuation** (replacing non-alphanumeric characters with spaces).\n",
    "3. **Tokenizing** (splitting the text into words).\n",
    "4. Removing **stop words** (common words that don't contribute much meaning).\n",
    "5. Applying **lemmatization** (reducing words to their base form).\n",
    "\n",
    "If the input is not a string, it returns an empty string.\n",
    "\n",
    "### 2. replace_abbreviations\n",
    "Replaces known abbreviations in a given text using the `abbreviation_mapping` dictionary.\n",
    "- Splits the text into words.\n",
    "- Replaces each word if it exists in the abbreviation dictionary.\n",
    "- Returns the modified text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  loinc_num                                               name  \\\n",
      "0   33870-7               bilirubin total unspecified specimen   \n",
      "1   29265-6             calcium corrected albumin serum plasma   \n",
      "2   14423-8                     bilirubin total synovial fluid   \n",
      "3   23658-8                                         antibiotic   \n",
      "4   19000-9                                         vancomycin   \n",
      "5   14749-6                               glucose serum plasma   \n",
      "6    1920-8            aspartate aminotransferase serum plasma   \n",
      "7   18878-9                                          cefazolin   \n",
      "8   20442-0  hepatitis b virus dna viral load serum probe s...   \n",
      "9    1751-7                               albumin serum plasma   \n",
      "\n",
      "                    component        system                 property  \\\n",
      "0                   bilirubin           xxx                    prthr   \n",
      "1   calcium corrected albumin  serum plasma  substance concentration   \n",
      "2                   bilirubin    synv field       mass concentration   \n",
      "3              antibiotic xxx       isolate           susceptibility   \n",
      "4                  vancomycin       isolate           susceptibility   \n",
      "5                     glucose  serum plasma  substance concentration   \n",
      "6  aspartate aminotransferase  serum plasma       cell concentration   \n",
      "7                   cefazolin       isolate           susceptibility   \n",
      "8       hepatitis b virus dna         serum     number concentration   \n",
      "9                     albumin  serum plasma       mass concentration   \n",
      "\n",
      "            measurement_type  \n",
      "0                   presence  \n",
      "1                mole volume  \n",
      "2                mass volume  \n",
      "3             susceptibility  \n",
      "4             susceptibility  \n",
      "5                mole volume  \n",
      "6  enzymatic activity volume  \n",
      "7             susceptibility  \n",
      "8                     volume  \n",
      "9                mass volume  \n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower() \n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)  \n",
    "        words = text.split()  \n",
    "        words = [word for word in words if word not in stop_words]  \n",
    "        words = [lemmatizer.lemmatize(word) for word in words] \n",
    "        return \" \".join(words)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def replace_abbreviations(text):\n",
    "    if isinstance(text, str):\n",
    "        words = text.split()\n",
    "        words = [abbreviation_mapping.get(word, word) for word in words]  \n",
    "        return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "\n",
    "for col in query_df.select_dtypes(include=[\"object\"]).columns:\n",
    "    if col != \"loinc_num\":  \n",
    "        query_df[col] = query_df[col].apply(clean_text)\n",
    "        query_df[col] = query_df[col].apply(replace_abbreviations)\n",
    "\n",
    "print(query_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Weights and Embedding Model Initialization\n",
    "\n",
    "This script defines **column weights** for a scoring system and initializes an **embedding model** for text similarity calculations.\n",
    "\n",
    "## Column Weights\n",
    "\n",
    "The `column_weights` dictionary assigns importance to different columns when calculating scores:\n",
    "\n",
    "- **Higher weights** (e.g., `name`, `component`) indicate greater importance in the scoring process.\n",
    "- `loinc_num` has a weight of **0** because it is likely an identifier and does not contribute to similarity calculations.\n",
    "\n",
    "## Embedding Model Initialization\n",
    "\n",
    "The script attempts to load an embedding model for text similarity using **SentenceTransformer**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_weights = {\n",
    "    'name': 1.5,\n",
    "    'component': 6.0,\n",
    "    'long_common_name': 1.0,\n",
    "    'system': 3.0,\n",
    "    'property': 1.0,\n",
    "    'measurement_type': 1.0,\n",
    "    'loinc_num': 0\n",
    "}\n",
    "\n",
    "global embedding_model\n",
    "if 'embedding_model' not in globals():\n",
    "    try:\n",
    "        embedding_model = SentenceTransformer('pritamdeka/BioBERT-MNLI')\n",
    "    except:\n",
    "        try:\n",
    "            embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        except:\n",
    "            embedding_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevance Score Calculation\n",
    "This script calculates a **relevance score** for each row in a dataset by comparing a query to the dataset's text fields using both **traditional keyword matching** and **semantic similarity via embeddings**.\n",
    "\n",
    "\n",
    "### 1. calculate_score\n",
    "This function calculates the relevance score for a given row by:\n",
    "1. Splitting the query into words and storing them in a set.\n",
    "2. Initializing an empty dictionary to track matched words.\n",
    "3. Computing the **traditional** relevance score.\n",
    "4. Computing the **embedding-based** relevance score.\n",
    "5. Combining both scores and optionally printing debug information.\n",
    "\n",
    "\n",
    "### 2. get_query_embedding\n",
    "Encodes the query into an **embedding vector** using a pre-trained embedding model.\n",
    "- If the embedding model is available, it encodes the query.\n",
    "- If an error occurs, it prints an error message and returns `None`.\n",
    "\n",
    "### 3. calculate_traditional_score\n",
    "This function calculates a **keyword matching score** based on:\n",
    "- The presence of query words in the main columns `component` and `system`\n",
    "- A predefined weight assigned to each column.\n",
    "\n",
    "### 4. calculate_embedding_score\n",
    "This function computes the **semantic similarity score** between the query embedding and the row's text fields:\n",
    "- Encodes the text field into an embedding.\n",
    "- Uses **cosine similarity** to measure similarity between the query and field.\n",
    "- Converts the similarity score (ranging from -1 to 1) into a normalized range.\n",
    "- Applies column weights to adjust the score.\n",
    "- Adds the result to the final score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(query, query_df, row, debug=False):\n",
    "    query_embedding = get_query_embedding(query)\n",
    "    debug_info = {\"query\": query, \"embedding_score\": [], \"traditional_score\": []}\n",
    "    \n",
    "    traditional_score = calculate_traditional_score(query, row, debug_info)\n",
    "    embedding_score = calculate_embedding_score(query_embedding, query_df, row, debug_info)\n",
    "    score = traditional_score + embedding_score\n",
    "    \n",
    "    debug_info[\"final_score\"] = score\n",
    "    \n",
    "    if debug:\n",
    "        print(debug_info)\n",
    "   \n",
    "    return score\n",
    "\n",
    "\n",
    "def get_query_embedding(query):\n",
    "    if embedding_model:\n",
    "        try:\n",
    "            return embedding_model.encode(query.lower())\n",
    "        except Exception as e:\n",
    "            print(f\"Embedding encoding error: {e}\")\n",
    "    return None\n",
    "\n",
    "def calculate_traditional_score(query, row, debug_info):\n",
    "    score = 0\n",
    "    \n",
    "    query_component = query_mapping[query][\"component\"].lower()\n",
    "    query_system = query_mapping[query][\"system\"].lower()\n",
    "\n",
    "    component = row.get(\"component\", \"\").lower() \n",
    "    system = row.get(\"system\", \"\").lower()  \n",
    "    \n",
    "    if query_component == component:\n",
    "        score += column_weights.get(\"component\", 1.0)  * column_weights.get(\"component\", 1.0) \n",
    "    elif query_component in component:\n",
    "        score += (column_weights.get(\"component\", 1.0) * 0.5) * column_weights.get(\"component\", 1.0)   \n",
    "    \n",
    "    if query_system == system:\n",
    "        score += column_weights.get(\"system\", 1.0)  * column_weights.get(\"system\", 1.0)  \n",
    "    elif query_system in system:\n",
    "        score += (column_weights.get(\"system\", 1.0) * 0.5) * column_weights.get(\"system\", 1.0)   \n",
    "\n",
    "    debug_info[\"traditional_score\"].append({\"score\": score})\n",
    "        \n",
    "    return score\n",
    "\n",
    "def calculate_embedding_score(query_embedding, query_df, row, debug_info):\n",
    "    score = 0\n",
    "    if embedding_model and query_embedding is not None:\n",
    "        for col in query_df.select_dtypes(include=[\"object\"]).columns:\n",
    "            if col in row and pd.notna(row[col]):\n",
    "                cell_text = str(row[col]).lower()\n",
    "                weight = column_weights.get(col, 1.0)\n",
    "                try:\n",
    "                    cell_embedding = embedding_model.encode(cell_text)\n",
    "                    similarity = cosine_similarity([query_embedding], [cell_embedding])[0][0]\n",
    "                    embedding_score = ((similarity + 1) / 2) * 5 * weight\n",
    "                    score += embedding_score\n",
    "                except Exception as e:\n",
    "                    print(f\"Embedding similarity error: {e}\")\n",
    "        debug_info[\"embedding_score\"].append({\"score\": score})\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of the file\n",
    "This script processes an Excel file, calculates relevance scores for each row based on a query, normalizes the scores, and saves the results to a CSV file. The relevance scores are computed using both traditional keyword matching and embeddings.\n",
    "\n",
    "### 1. Data Preprocessing\n",
    "   - Loads the Excel file and iterates over each sheet.\n",
    "   - Renames columns for consistency and extracts relevant information (e.g., measurement type) from the `name` column.\n",
    "   - Cleans and strips spaces from column names.\n",
    "\n",
    "### 2. Score Calculation\n",
    "   - For each row, a relevance score is computed using `calculate_score`.\n",
    "   - Debug information is printed for the first 5 rows.\n",
    "\n",
    "### 3.Normalization\n",
    "   - The minimum and maximum scores are calculated, and a new column for normalized scores is added using the formula `(score - min_score) / (max_score - min_score)`.\n",
    "\n",
    "### 4. Results\n",
    "   - The results (Query, LOINC Code, Name, Score, Normalized Score) are saved to a CSV file: `dataset_with_scores.csv`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(35.774864)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(35.774864)}\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(38.686966)}], 'traditional_score': [{'score': 9.0}], 'final_score': np.float32(47.686966)}\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(36.613216)}], 'traditional_score': [{'score': 9.0}], 'final_score': np.float32(45.613216)}\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(32.27971)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(32.27971)}\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(37.938316)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(37.938316)}\n",
      "{'query': 'bilirubin in plasma', 'embedding_score': [{'score': np.float32(37.021507)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(37.021507)}\n",
      "{'query': 'bilirubin in plasma', 'embedding_score': [{'score': np.float32(40.582455)}], 'traditional_score': [{'score': 4.5}], 'final_score': np.float32(45.082455)}\n",
      "{'query': 'bilirubin in plasma', 'embedding_score': [{'score': np.float32(35.76241)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(35.76241)}\n",
      "{'query': 'bilirubin in plasma', 'embedding_score': [{'score': np.float32(41.30145)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(41.30145)}\n",
      "{'query': 'bilirubin in plasma', 'embedding_score': [{'score': np.float32(35.153305)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(35.153305)}\n",
      "{'query': 'white blood cells count', 'embedding_score': [{'score': np.float32(33.414078)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(33.414078)}\n",
      "{'query': 'white blood cells count', 'embedding_score': [{'score': np.float32(35.18252)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(35.18252)}\n",
      "{'query': 'white blood cells count', 'embedding_score': [{'score': np.float32(34.961994)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(34.961994)}\n",
      "{'query': 'white blood cells count', 'embedding_score': [{'score': np.float32(33.06633)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(33.06633)}\n",
      "{'query': 'white blood cells count', 'embedding_score': [{'score': np.float32(31.95425)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(31.95425)}\n",
      "CSV with relevance scores has been saved as 'dataset_with_scores.csv'.\n"
     ]
    }
   ],
   "source": [
    "min_score = float(\"inf\")\n",
    "max_score = float(\"-inf\")\n",
    "\n",
    "\n",
    "def preprocess(excel_file):\n",
    "    results = []\n",
    "    xl = pd.ExcelFile(excel_file)\n",
    "\n",
    "    for sheet_name in xl.sheet_names:\n",
    "        query_df = xl.parse(sheet_name, header=2)\n",
    "        sheet_name = sheet_name.lower()\n",
    "         \n",
    "        query_df.rename(columns={\"long_common_name\": \"name\"}, inplace=True)\n",
    "        query_df[\"measurement_type\"] = query_df[\"name\"].apply(lambda x: re.findall(r\"\\[(.*?)\\]\", x)[0] if \"[\" in x else \"\")\n",
    "        query_df[\"name\"] = query_df[\"name\"].apply(lambda x: re.sub(r\"\\[.*?\\]\", \"\", x).strip() if isinstance(x, str) else x)\n",
    "\n",
    "        for col in query_df.select_dtypes(include=[\"object\"]).columns:\n",
    "            if col != \"loinc_num\":  \n",
    "                query_df[col] = query_df[col].apply(clean_text)\n",
    "                query_df[col] = query_df[col].apply(replace_abbreviations)\n",
    "            \n",
    "        query_df.columns = query_df.columns.str.strip()  \n",
    "        \n",
    "        if len(query_df.columns) < 4:\n",
    "            print(f\"Skipping sheet '{sheet_name}': Missing required columns\")\n",
    "            continue\n",
    "        \n",
    "        for _, row in query_df.iterrows():\n",
    "            score = calculate_score(sheet_name, query_df, row, debug=True if row.name < 5 else False)\n",
    "            results.append([sheet_name, row.iloc[0], row.iloc[1], row.iloc[2], row.iloc[3], row.iloc[4], row.iloc[5], score])\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=[\"Query\", \"LOINC Code\", \"Name\", \"Component\", \"System\", \"Property\", \"Measurement\", \"Score\"])\n",
    "\n",
    "    min_score = results_df[\"Score\"].min()\n",
    "    max_score = results_df[\"Score\"].max()\n",
    "\n",
    "    results_df[\"Normalized_Score\"] = results_df[\"Score\"].apply(lambda score: (score - min_score) / (max_score - min_score) if max_score != min_score else 1.0)\n",
    "    results_df.drop(columns=[\"Score\"], inplace=True)\n",
    "\n",
    "    results_df.to_csv(\"dataset_with_scores.csv\", index=False)\n",
    "    print(\"CSV with relevance scores has been saved as 'dataset_with_scores.csv'.\")\n",
    "\n",
    "\n",
    "\n",
    "results_df = preprocess(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
