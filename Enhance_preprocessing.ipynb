{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "\n",
    "\n",
    "query_mapping = {\n",
    "    \"glucose in blood\": {\n",
    "        \"component\": \"glucose\",\n",
    "        \"system\": \"blood\"\n",
    "    },\n",
    "    \"bilirubin in plasma\": {\n",
    "        \"component\": \"bilirubin\",\n",
    "        \"system\": \"plasma\"\n",
    "    },\n",
    "    \"white blood cells count\": {\n",
    "        \"component\": \"leukocytes\",\n",
    "        \"system\": \"blood\"\n",
    "    },\n",
    "    \"calcium in serum\": {\n",
    "        \"component\": \"calcium\",\n",
    "        \"system\": \"serum\"\n",
    "    },\n",
    "     \"cells in urine\": {\n",
    "        \"component\": \"cells\",\n",
    "        \"system\": \"urine\"\n",
    "    }\n",
    "}\n",
    "\n",
    "file_path = \"./LOINC_Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joseantonioruizheredia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/joseantonioruizheredia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "abbreviation_mapping = {\n",
    "    'c': 'component',\n",
    "    'mcnc': 'mass concentration',\n",
    "    'bld': 'blood',\n",
    "    'scnc': 'substance concentration',\n",
    "    'susc': 'susceptibility',\n",
    "    'acnc': 'amount concentration',\n",
    "    'plas': 'plasma',\n",
    "    'ccnc': 'cell concentration',\n",
    "    'ncnc': 'number concentration',\n",
    "    'XXX': 'unknown',\n",
    "    '^bpu': 'body part or unit',\n",
    "    'fld': 'field',\n",
    "    'abo': 'abo blood group',\n",
    "    'ser': 'serum',\n",
    "    'mscnc': 'mass substance concentration',\n",
    "    'ser/plas': 'serum or plasma'\n",
    "}\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower() \n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)  \n",
    "        words = text.split()  \n",
    "        words = [word for word in words if word not in stop_words]  \n",
    "        words = [lemmatizer.lemmatize(word) for word in words] \n",
    "        return \" \".join(words)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def replace_abbreviations(text):\n",
    "    if isinstance(text, str):\n",
    "        words = text.split()\n",
    "        words = [abbreviation_mapping.get(word, word) for word in words]  \n",
    "        return \" \".join(words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_weights = {\n",
    "    'name': 1.5,\n",
    "    'component': 6.0,\n",
    "    'long_common_name': 1.0,\n",
    "    'system': 3.0,\n",
    "    'property': 1.0,\n",
    "    'measurement_type': 1.0,\n",
    "    'loinc_num': 0,\n",
    "    'status': 0.5,\n",
    "    'example_units': 1.0\n",
    "}\n",
    "\n",
    "global embedding_model\n",
    "if 'embedding_model' not in globals():\n",
    "    try:\n",
    "        embedding_model = SentenceTransformer('pritamdeka/BioBERT-MNLI')\n",
    "    except:\n",
    "        try:\n",
    "            embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        except:\n",
    "            embedding_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(query, query_df, row, debug=False):\n",
    "    query_embedding = get_query_embedding(query)\n",
    "    debug_info = {\"query\": query, \"embedding_score\": [], \"traditional_score\": []}\n",
    "    \n",
    "    traditional_score = calculate_traditional_score(query, row, debug_info)\n",
    "    embedding_score = calculate_embedding_score(query_embedding, query_df, row, debug_info)\n",
    "    score = traditional_score + embedding_score\n",
    "    \n",
    "    debug_info[\"final_score\"] = score\n",
    "    \n",
    "    if debug:\n",
    "        print(debug_info)\n",
    "   \n",
    "    return score\n",
    "\n",
    "\n",
    "def get_query_embedding(query):\n",
    "    if embedding_model:\n",
    "        try:\n",
    "            return embedding_model.encode(query.lower())\n",
    "        except Exception as e:\n",
    "            print(f\"Embedding encoding error: {e}\")\n",
    "    return None\n",
    "\n",
    "def calculate_traditional_score(query, row, debug_info):\n",
    "    score = 0\n",
    "    \n",
    "    query_component = query_mapping[query][\"component\"].lower()\n",
    "    query_system = query_mapping[query][\"system\"].lower()\n",
    "\n",
    "\n",
    "    component = row.get(\"COMPONENT\", \"\").lower() \n",
    "    system = row.get(\"SYSTEM\", \"\").lower()  \n",
    "    \n",
    "    if query_component == component:\n",
    "        score += column_weights.get(\"component\", 1.0)  * column_weights.get(\"component\", 1.0) \n",
    "    elif query_component in component:\n",
    "        score += (column_weights.get(\"component\", 1.0) * 0.5) * column_weights.get(\"component\", 1.0)   \n",
    "    \n",
    "    if query_system == system:\n",
    "        score += column_weights.get(\"system\", 1.0)  * column_weights.get(\"system\", 1.0)  \n",
    "    elif query_system in system:\n",
    "        score += (column_weights.get(\"system\", 1.0) * 0.5) * column_weights.get(\"system\", 1.0) \n",
    "\n",
    "    debug_info[\"traditional_score\"].append({\"score\": score})\n",
    "        \n",
    "    return score\n",
    "\n",
    "def calculate_embedding_score(query_embedding, query_df, row, debug_info):\n",
    "    score = 0\n",
    "    if embedding_model and query_embedding is not None:\n",
    "        for col in query_df.select_dtypes(include=[\"object\"]).columns:\n",
    "            if col in row and pd.notna(row[col]):\n",
    "                cell_text = str(row[col]).lower()\n",
    "                weight = column_weights.get(col, 1.0)\n",
    "                try:\n",
    "                    cell_embedding = embedding_model.encode(cell_text)\n",
    "                    similarity = cosine_similarity([query_embedding], [cell_embedding])[0][0]\n",
    "                    embedding_score = ((similarity + 1) / 2) * 5 * weight\n",
    "                    score += embedding_score\n",
    "                except Exception as e:\n",
    "                    print(f\"Embedding similarity error: {e}\")\n",
    "        debug_info[\"embedding_score\"].append({\"score\": score})\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query: glucose in blood\n",
      "Reading file: ./LOINC_Dataset/bilirubin_in_plasma.csv\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(44.857346)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(44.857346)}\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(43.959023)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(43.959023)}\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(44.26867)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(44.26867)}\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(45.496178)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(45.496178)}\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(45.245346)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(45.245346)}\n",
      "Reading file: ./LOINC_Dataset/cells_in_urine.csv\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(42.057995)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(42.057995)}\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(41.484337)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(41.484337)}\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(41.12508)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(41.12508)}\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(41.85633)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(41.85633)}\n",
      "{'query': 'glucose in blood', 'embedding_score': [{'score': np.float32(42.378197)}], 'traditional_score': [{'score': 0}], 'final_score': np.float32(42.378197)}\n"
     ]
    }
   ],
   "source": [
    "def process_folder(csv_folder):\n",
    "    csv_files = [f for f in os.listdir(csv_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "    for query_name, _ in query_mapping.items():\n",
    "        results = []\n",
    "\n",
    "        print(f\"Processing query: {query_name}\")\n",
    "\n",
    "        for csv_file in csv_files:\n",
    "            file_path = os.path.join(csv_folder, csv_file)\n",
    "            print(f\"Reading file: {file_path}\")\n",
    "\n",
    "            try:\n",
    "                dataset = pd.read_csv(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {csv_file} due to read error: {e}\")\n",
    "                continue  \n",
    "            \n",
    "            dataset.columns = dataset.columns.str.strip().str.upper()\n",
    "            \n",
    "            dataset.rename(columns={\"LONG_COMMON_NAME\": \"NAME\"}, inplace=True)\n",
    "            dataset[\"MEASUREMENT_TYPE\"] = dataset[\"NAME\"].apply(lambda x: re.findall(r\"\\[(.*?)\\]\", x)[0] if isinstance(x, str) and \"[\" in x else \"\")\n",
    "            \n",
    "            for col in dataset.select_dtypes(include=[\"object\"]).columns:\n",
    "                if col != \"LOINC_NUM\":  \n",
    "                    dataset[col] = dataset[col].apply(clean_text)\n",
    "                    dataset[col] = dataset[col].apply(replace_abbreviations)\n",
    "            \n",
    "            for _, row in dataset.iterrows():\n",
    "                score = calculate_score(query_name, dataset, row, debug=True if row.name < 5 else False)\n",
    "                results.append([query_name, row.iloc[0], row.iloc[14], row.iloc[1], row.iloc[4], row.iloc[2], row.iloc[19], row.iloc[9], row.iloc[13], score])\n",
    "\n",
    "    if results:\n",
    "        results_df = pd.DataFrame(results, columns=[\"Query\", \"LOINC Code\", \"Name\", \"Component\", \"System\", \"Property\", \"Measurement\", \"Status\", \"Units\", \"Score\"])\n",
    "\n",
    "        min_score, max_score = results_df[\"Score\"].min(), results_df[\"Score\"].max()\n",
    "        results_df[\"Normalized_Score\"] = results_df[\"Score\"].apply(lambda s: (s - min_score) / (max_score - min_score) if max_score != min_score else 1.0)\n",
    "        results_df.drop(columns=[\"Score\"], inplace=True)\n",
    "\n",
    "        output_filename = f\"results_enhanced.csv\"\n",
    "        results_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Results saved to {output_filename}\")\n",
    "\n",
    "process_folder(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
